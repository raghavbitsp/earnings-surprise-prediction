{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c617afee-38e9-4b70-96d0-243017cbcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0633c268-5552-43f2-85e5-35c220389c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>eps</th>\n",
       "      <th>revenue</th>\n",
       "      <th>pat_margin</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>pat</th>\n",
       "      <th>company</th>\n",
       "      <th>ret_1m</th>\n",
       "      <th>ret_3m</th>\n",
       "      <th>vol_30d</th>\n",
       "      <th>vol_60d</th>\n",
       "      <th>abnormal_volume</th>\n",
       "      <th>qtr_Q2</th>\n",
       "      <th>qtr_Q3</th>\n",
       "      <th>qtr_Q4</th>\n",
       "      <th>covid_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017Q2</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3598.12</td>\n",
       "      <td>4.86</td>\n",
       "      <td>326.05</td>\n",
       "      <td>9.06</td>\n",
       "      <td>174.77</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.297413</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.025774</td>\n",
       "      <td>0.711724</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3506.92</td>\n",
       "      <td>5.45</td>\n",
       "      <td>339.14</td>\n",
       "      <td>9.67</td>\n",
       "      <td>191.04</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.323089</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>2.377819</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017Q4</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4093.89</td>\n",
       "      <td>6.15</td>\n",
       "      <td>435.40</td>\n",
       "      <td>10.64</td>\n",
       "      <td>251.77</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>0.131616</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.816669</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3809.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>309.38</td>\n",
       "      <td>8.12</td>\n",
       "      <td>167.10</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.151850</td>\n",
       "      <td>0.021122</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4559.42</td>\n",
       "      <td>5.50</td>\n",
       "      <td>436.93</td>\n",
       "      <td>9.58</td>\n",
       "      <td>250.61</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>0.094379</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0.281471</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter   eps  revenue  pat_margin  ebitda  ebitda_margin     pat company  \\\n",
       "0  2017Q2  2.80  3598.12        4.86  326.05           9.06  174.77  AVENUE   \n",
       "1  2017Q3  3.06  3506.92        5.45  339.14           9.67  191.04  AVENUE   \n",
       "2  2017Q4  4.03  4093.89        6.15  435.40          10.64  251.77  AVENUE   \n",
       "3  2018Q1  2.68  3809.96        4.39  309.38           8.12  167.10  AVENUE   \n",
       "4  2018Q2  4.02  4559.42        5.50  436.93           9.58  250.61  AVENUE   \n",
       "\n",
       "     ret_1m    ret_3m   vol_30d   vol_60d  abnormal_volume  qtr_Q2  qtr_Q3  \\\n",
       "0  0.093874  0.297413  0.013936  0.025774         0.711724    True   False   \n",
       "1  0.037171  0.323089  0.026681  0.022271         2.377819   False    True   \n",
       "2  0.049576  0.131616  0.012112  0.019751         0.816669   False   False   \n",
       "3  0.026022  0.151850  0.021122  0.019811         0.786405   False   False   \n",
       "4 -0.055179  0.094379  0.024817  0.020871         0.281471    True   False   \n",
       "\n",
       "   qtr_Q4  covid_dummy  \n",
       "0   False            0  \n",
       "1   False            0  \n",
       "2    True            0  \n",
       "3   False            0  \n",
       "4   False            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_ml_dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e369212-4bac-4601-abcd-0460e4101952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " 'get_ipython',\n",
       " 'exit',\n",
       " 'quit',\n",
       " 'open',\n",
       " 'json',\n",
       " 'getpass',\n",
       " 'hashlib',\n",
       " 'import_pandas_safely',\n",
       " 'is_data_frame',\n",
       " 'dataframe_columns',\n",
       " 'dtypes_str',\n",
       " 'dataframe_hash',\n",
       " 'get_dataframes',\n",
       " 'pd',\n",
       " 'np',\n",
       " 'df']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dataframes now\n",
    "[var for var in globals().keys() if not var.startswith(\"_\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7795ff-de05-4a7a-8b36-7a8c27c98a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (712, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>eps</th>\n",
       "      <th>revenue</th>\n",
       "      <th>pat_margin</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>pat</th>\n",
       "      <th>company</th>\n",
       "      <th>ret_1m</th>\n",
       "      <th>ret_3m</th>\n",
       "      <th>vol_30d</th>\n",
       "      <th>vol_60d</th>\n",
       "      <th>abnormal_volume</th>\n",
       "      <th>qtr_Q2</th>\n",
       "      <th>qtr_Q3</th>\n",
       "      <th>qtr_Q4</th>\n",
       "      <th>covid_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017Q2</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3598.12</td>\n",
       "      <td>4.86</td>\n",
       "      <td>326.05</td>\n",
       "      <td>9.06</td>\n",
       "      <td>174.77</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.093874</td>\n",
       "      <td>0.297413</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.025774</td>\n",
       "      <td>0.711724</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3506.92</td>\n",
       "      <td>5.45</td>\n",
       "      <td>339.14</td>\n",
       "      <td>9.67</td>\n",
       "      <td>191.04</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.323089</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>2.377819</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017Q4</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4093.89</td>\n",
       "      <td>6.15</td>\n",
       "      <td>435.40</td>\n",
       "      <td>10.64</td>\n",
       "      <td>251.77</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>0.131616</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.816669</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3809.96</td>\n",
       "      <td>4.39</td>\n",
       "      <td>309.38</td>\n",
       "      <td>8.12</td>\n",
       "      <td>167.10</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.151850</td>\n",
       "      <td>0.021122</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.786405</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4559.42</td>\n",
       "      <td>5.50</td>\n",
       "      <td>436.93</td>\n",
       "      <td>9.58</td>\n",
       "      <td>250.61</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>0.094379</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0.281471</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter   eps  revenue  pat_margin  ebitda  ebitda_margin     pat company  \\\n",
       "0  2017Q2  2.80  3598.12        4.86  326.05           9.06  174.77  AVENUE   \n",
       "1  2017Q3  3.06  3506.92        5.45  339.14           9.67  191.04  AVENUE   \n",
       "2  2017Q4  4.03  4093.89        6.15  435.40          10.64  251.77  AVENUE   \n",
       "3  2018Q1  2.68  3809.96        4.39  309.38           8.12  167.10  AVENUE   \n",
       "4  2018Q2  4.02  4559.42        5.50  436.93           9.58  250.61  AVENUE   \n",
       "\n",
       "     ret_1m    ret_3m   vol_30d   vol_60d  abnormal_volume  qtr_Q2  qtr_Q3  \\\n",
       "0  0.093874  0.297413  0.013936  0.025774         0.711724    True   False   \n",
       "1  0.037171  0.323089  0.026681  0.022271         2.377819   False    True   \n",
       "2  0.049576  0.131616  0.012112  0.019751         0.816669   False   False   \n",
       "3  0.026022  0.151850  0.021122  0.019811         0.786405   False   False   \n",
       "4 -0.055179  0.094379  0.024817  0.020871         0.281471    True   False   \n",
       "\n",
       "   qtr_Q4  covid_dummy  \n",
       "0   False            0  \n",
       "1   False            0  \n",
       "2    True            0  \n",
       "3   False            0  \n",
       "4   False            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccdd9752-543c-4dd9-aeb4-6d62e2b952fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# sort properly (VERY IMPORTANT)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mdf\u001b[49m.sort_values([\u001b[33m\"\u001b[39m\u001b[33mcompany\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mquarter\u001b[39m\u001b[33m\"\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# create eps lag of 4 quarters (YoY)\u001b[39;00m\n\u001b[32m      5\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33meps_lag4\u001b[39m\u001b[33m\"\u001b[39m] = df.groupby(\u001b[33m\"\u001b[39m\u001b[33mcompany\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33meps\u001b[39m\u001b[33m\"\u001b[39m].shift(\u001b[32m4\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# sort properly (VERY IMPORTANT)\n",
    "df = df.sort_values([\"company\", \"quarter\"]).reset_index(drop=True)\n",
    "\n",
    "# create eps lag of 4 quarters (YoY)\n",
    "df[\"eps_lag4\"] = df.groupby(\"company\")[\"eps\"].shift(4)\n",
    "\n",
    "# target variable: earnings surprise\n",
    "df[\"surprise\"] = (df[\"eps\"] > df[\"eps_lag4\"]).astype(int)\n",
    "\n",
    "df[[\"company\", \"quarter\", \"eps\", \"eps_lag4\", \"surprise\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0f4549-c8f0-4203-862a-38e4870e76b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>quarter</th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_lag1</th>\n",
       "      <th>eps_lag2</th>\n",
       "      <th>eps_lag4</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2017Q2</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2017Q3</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2017Q4</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q1</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q3</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q4</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q2</td>\n",
       "      <td>5.37</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q3</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.37</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q4</td>\n",
       "      <td>6.30</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2020Q1</td>\n",
       "      <td>4.49</td>\n",
       "      <td>6.30</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company quarter   eps  eps_lag1  eps_lag2  eps_lag4  surprise\n",
       "0   AVENUE  2017Q2  2.80       NaN       NaN       NaN         0\n",
       "1   AVENUE  2017Q3  3.06      2.80       NaN       NaN         0\n",
       "2   AVENUE  2017Q4  4.03      3.06      2.80       NaN         0\n",
       "3   AVENUE  2018Q1  2.68      4.03      3.06       NaN         0\n",
       "4   AVENUE  2018Q2  4.02      2.68      4.03      2.80         1\n",
       "5   AVENUE  2018Q3  3.62      4.02      2.68      3.06         1\n",
       "6   AVENUE  2018Q4  4.12      3.62      4.02      4.03         1\n",
       "7   AVENUE  2019Q1  3.25      4.12      3.62      2.68         1\n",
       "8   AVENUE  2019Q2  5.37      3.25      4.12      4.02         1\n",
       "9   AVENUE  2019Q3  5.34      5.37      3.25      3.62         1\n",
       "10  AVENUE  2019Q4  6.30      5.34      5.37      4.12         1\n",
       "11  AVENUE  2020Q1  4.49      6.30      5.34      3.25         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lagged EPS features\n",
    "df[\"eps_lag1\"] = df.groupby(\"company\")[\"eps\"].shift(1)\n",
    "df[\"eps_lag2\"] = df.groupby(\"company\")[\"eps\"].shift(2)\n",
    "\n",
    "df[[\n",
    "    \"company\", \"quarter\",\n",
    "    \"eps\", \"eps_lag1\", \"eps_lag2\", \"eps_lag4\", \"surprise\"\n",
    "]].head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0817e1-7129-44a8-8215-3b9524fcd5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(632, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = df.dropna(subset=[\n",
    "    \"eps_lag1\", \"eps_lag2\", \"eps_lag4\",\n",
    "    \"ret_1m\", \"ret_3m\", \"vol_30d\", \"vol_60d\", \"abnormal_volume\"\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "model_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475979d8-c6d4-44e8-bd12-9610fbfc2bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df2fecf-1792-493b-b4f7-4130956ac97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((632, 17), (632,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target\n",
    "y = model_df[\"surprise\"]\n",
    "\n",
    "# features to EXCLUDE\n",
    "exclude_cols = [\n",
    "    \"surprise\",\n",
    "    \"company\",\n",
    "    \"quarter\",\n",
    "    \"eps\"   # current EPS must NOT be a feature\n",
    "]\n",
    "\n",
    "X = model_df.drop(columns=exclude_cols)\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d412d68-d747-494f-a32b-5665bf65d9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique quarters in chronological order\n",
    "quarters = sorted(model_df[\"quarter\"].unique())\n",
    "\n",
    "# helper to extract year\n",
    "def q_year(q):\n",
    "    return int(q[:4])\n",
    "\n",
    "# define test years (we ensure real OOS testing)\n",
    "test_years = sorted(set(q_year(q) for q in quarters))[3:]  \n",
    "# we skip early years to ensure enough training data\n",
    "\n",
    "splits = []\n",
    "\n",
    "for year in test_years:\n",
    "    test_quarters = [q for q in quarters if q.startswith(str(year))]\n",
    "    train_quarters = [q for q in quarters if q < test_quarters[0]]\n",
    "\n",
    "    if len(test_quarters) == 4 and len(train_quarters) > 0:\n",
    "        splits.append((train_quarters, test_quarters))\n",
    "\n",
    "len(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4ddc96-90af-4e8a-9b95-fe49ea91315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN QUARTERS:\n",
      "['2016Q4', '2017Q1', '2017Q2', '2017Q3', '2017Q4'] ... ['2017Q4', '2018Q1', '2018Q2', '2018Q3', '2018Q4']\n",
      "\n",
      "TEST QUARTERS:\n",
      "['2019Q1', '2019Q2', '2019Q3', '2019Q4']\n"
     ]
    }
   ],
   "source": [
    "# inspect first split\n",
    "train_q, test_q = splits[0]\n",
    "\n",
    "print(\"TRAIN QUARTERS:\")\n",
    "print(train_q[:5], \"...\", train_q[-5:])\n",
    "\n",
    "print(\"\\nTEST QUARTERS:\")\n",
    "print(test_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3bb381-0f73-416a-9c0e-211509954eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8289473684210527, 0.6257575757575758)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# get first split\n",
    "train_quarters, test_quarters = splits[0]\n",
    "\n",
    "# split data\n",
    "train_df = model_df[model_df[\"quarter\"].isin(train_quarters)]\n",
    "test_df  = model_df[model_df[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "X_train = train_df[X.columns]\n",
    "y_train = train_df[\"surprise\"]\n",
    "\n",
    "X_test = test_df[X.columns]\n",
    "y_test = test_df[\"surprise\"]\n",
    "\n",
    "# train logistic regression\n",
    "logit = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = logit.predict(X_test)\n",
    "y_prob = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "acc, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4667415d-5a0a-415e-819f-237dc68e8ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8421052631578947, 0.5818181818181818)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# get first split\n",
    "train_quarters, test_quarters = splits[0]\n",
    "\n",
    "train_df = model_df[model_df[\"quarter\"].isin(train_quarters)]\n",
    "test_df  = model_df[model_df[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "X_train = train_df[X.columns]\n",
    "y_train = train_df[\"surprise\"]\n",
    "\n",
    "X_test = test_df[X.columns]\n",
    "y_test = test_df[\"surprise\"]\n",
    "\n",
    "# SCALE (fit only on training data)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# train logistic regression (scaled)\n",
    "logit = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred = logit.predict(X_test_scaled)\n",
    "y_prob = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "acc, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbeb768-cf36-4a0b-9da9-89e14304771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_year</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.701351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.757735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.807827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.717091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold test_year  accuracy       auc\n",
       "0     1      2019  0.842105  0.581818\n",
       "1     2      2020  0.623377  0.701351\n",
       "2     3      2021  0.625000  0.579500\n",
       "3     4      2022  0.650000  0.757735\n",
       "4     5      2023  0.725000  0.807827\n",
       "5     6      2024  0.737500  0.717091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, (train_quarters, test_quarters) in enumerate(splits):\n",
    "    train_df = model_df[model_df[\"quarter\"].isin(train_quarters)]\n",
    "    test_df  = model_df[model_df[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "    X_train = train_df[X.columns]\n",
    "    y_train = train_df[\"surprise\"]\n",
    "\n",
    "    X_test = test_df[X.columns]\n",
    "    y_test = test_df[\"surprise\"]\n",
    "\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    # model\n",
    "    logit = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "    logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # predict\n",
    "    y_pred = logit.predict(X_test_scaled)\n",
    "    y_prob = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    results.append({\n",
    "        \"fold\": i + 1,\n",
    "        \"test_year\": test_quarters[0][:4],\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0fa900-8e93-4977-93bc-538cc7a93fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_year</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.684848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.695946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.512510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.654378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.760307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold test_year  accuracy       auc\n",
       "0     1      2019  0.710526  0.684848\n",
       "1     2      2020  0.636364  0.695946\n",
       "2     3      2021  0.625000  0.512510\n",
       "3     4      2022  0.712500  0.654378\n",
       "4     5      2023  0.737500  0.760307\n",
       "5     6      2024  0.687500  0.680000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "rf_results = []\n",
    "\n",
    "for i, (train_quarters, test_quarters) in enumerate(splits):\n",
    "    train_df = model_df[model_df[\"quarter\"].isin(train_quarters)]\n",
    "    test_df  = model_df[model_df[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "    X_train = train_df[X.columns]\n",
    "    y_train = train_df[\"surprise\"]\n",
    "\n",
    "    X_test = test_df[X.columns]\n",
    "    y_test = test_df[\"surprise\"]\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        min_samples_leaf=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    rf_results.append({\n",
    "        \"fold\": i + 1,\n",
    "        \"test_year\": test_quarters[0][:4],\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc\n",
    "    })\n",
    "\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "rf_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23386f56-1f77-474b-979b-9925db2a6c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from xgboost) (2.3.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\acer\\anaconda3\\lib\\site-packages (from xgboost) (1.16.3)\n",
      "Downloading xgboost-3.1.3-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/72.0 MB 7.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 4.5/72.0 MB 16.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 8.9/72.0 MB 18.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 12.8/72.0 MB 18.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 17.6/72.0 MB 19.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 22.0/72.0 MB 19.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 26.2/72.0 MB 19.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 30.7/72.0 MB 19.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 35.7/72.0 MB 19.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 40.1/72.0 MB 19.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 44.6/72.0 MB 19.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 48.5/72.0 MB 19.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 53.0/72.0 MB 19.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 57.1/72.0 MB 19.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 61.3/72.0 MB 19.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.5/72.0 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 70.0/72.0 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 18.9 MB/s  0:00:03\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25dc995b-d6e3-4ceb-bf44-61e14e8d7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_year</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.474242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.604520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.747202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.827393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold test_year  accuracy       auc\n",
       "0     1      2019  0.815789  0.474242\n",
       "1     2      2020  0.506494  0.724324\n",
       "2     3      2021  0.737500  0.604520\n",
       "3     4      2022  0.700000  0.747202\n",
       "4     5      2023  0.775000  0.827393\n",
       "5     6      2024  0.750000  0.727273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "xgb_results = []\n",
    "\n",
    "for i, (train_quarters, test_quarters) in enumerate(splits):\n",
    "    train_df = model_df[model_df[\"quarter\"].isin(train_quarters)]\n",
    "    test_df  = model_df[model_df[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "    X_train = train_df[X.columns]\n",
    "    y_train = train_df[\"surprise\"]\n",
    "\n",
    "    X_test = test_df[X.columns]\n",
    "    y_test = test_df[\"surprise\"]\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    y_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    xgb_results.append({\n",
    "        \"fold\": i + 1,\n",
    "        \"test_year\": test_quarters[0][:4],\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc\n",
    "    })\n",
    "\n",
    "xgb_results_df = pd.DataFrame(xgb_results)\n",
    "xgb_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa0dee6-39a4-4a85-8dd5-c708e4314b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>quarter</th>\n",
       "      <th>eps</th>\n",
       "      <th>eps_lag4</th>\n",
       "      <th>scaled_surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.435714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q3</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.183007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q4</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.022333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q1</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.212687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q2</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.335821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company quarter   eps  eps_lag4  scaled_surprise\n",
       "0  AVENUE  2018Q2  4.02      2.80         0.435714\n",
       "1  AVENUE  2018Q3  3.62      3.06         0.183007\n",
       "2  AVENUE  2018Q4  4.12      4.03         0.022333\n",
       "3  AVENUE  2019Q1  3.25      2.68         0.212687\n",
       "4  AVENUE  2019Q2  5.37      4.02         0.335821"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled earnings surprise\n",
    "model_df[\"scaled_surprise\"] = (\n",
    "    (model_df[\"eps\"] - model_df[\"eps_lag4\"]) / model_df[\"eps_lag4\"].abs()\n",
    ")\n",
    "\n",
    "model_df[[\"company\", \"quarter\", \"eps\", \"eps_lag4\", \"scaled_surprise\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7635945c-6062-4501-835a-bb3c8d355d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.24200913242009145), np.float64(0.006430868167202578))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute global quantile cutoffs\n",
    "upper_q = model_df[\"scaled_surprise\"].quantile(0.70)\n",
    "lower_q = model_df[\"scaled_surprise\"].quantile(0.30)\n",
    "\n",
    "upper_q, lower_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ee6ff1-e72d-47b0-a825-8ed50da12fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(surprise_q\n",
       " 1.0    190\n",
       " 0.0    190\n",
       " Name: count, dtype: int64,\n",
       " (380, 23))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize as NaN\n",
    "model_df[\"surprise_q\"] = np.nan\n",
    "\n",
    "# assign labels\n",
    "model_df.loc[model_df[\"scaled_surprise\"] >= upper_q, \"surprise_q\"] = 1\n",
    "model_df.loc[model_df[\"scaled_surprise\"] <= lower_q, \"surprise_q\"] = 0\n",
    "\n",
    "# drop noisy middle\n",
    "model_df_q = model_df.dropna(subset=[\"surprise_q\"]).reset_index(drop=True)\n",
    "\n",
    "model_df_q[\"surprise_q\"].value_counts(), model_df_q.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "597fc839-a8b2-4526-9efb-8ee5cd5abe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>gst_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016Q4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017Q2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2017Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017Q4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018Q4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019Q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter  gst_dummy\n",
       "14  2016Q4          0\n",
       "15  2017Q1          0\n",
       "40  2017Q2          0\n",
       "64  2017Q3          1\n",
       "16  2017Q4          1\n",
       "17  2018Q1          1\n",
       "0   2018Q2          1\n",
       "19  2018Q3          1\n",
       "20  2018Q4          1\n",
       "21  2019Q1          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GST dummy: 1 from 2017Q3 onwards\n",
    "model_df_q[\"gst_dummy\"] = (\n",
    "    model_df_q[\"quarter\"] >= \"2017Q3\"\n",
    ").astype(int)\n",
    "\n",
    "model_df_q[[\"quarter\", \"gst_dummy\"]].drop_duplicates().sort_values(\"quarter\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5b7a56-21a1-4a3f-8e52-e9e78cf1bcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['quarter', 'eps', 'revenue', 'pat_margin', 'ebitda', 'ebitda_margin',\n",
       "       'pat', 'company', 'ret_1m', 'ret_3m', 'vol_30d', 'vol_60d',\n",
       "       'abnormal_volume', 'qtr_Q2', 'qtr_Q3', 'qtr_Q4', 'covid_dummy',\n",
       "       'eps_lag4', 'surprise', 'eps_lag1', 'eps_lag2', 'scaled_surprise',\n",
       "       'surprise_q', 'gst_dummy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_q.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1caed131-65ec-4247-8d00-8ff203dcafed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>quarter</th>\n",
       "      <th>revenue_yoy</th>\n",
       "      <th>ebitda_yoy</th>\n",
       "      <th>pat_yoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2018Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2019Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2020Q1</td>\n",
       "      <td>0.358403</td>\n",
       "      <td>0.037374</td>\n",
       "      <td>0.144687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2020Q2</td>\n",
       "      <td>-0.336872</td>\n",
       "      <td>-0.736461</td>\n",
       "      <td>-0.852196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2020Q3</td>\n",
       "      <td>-0.122854</td>\n",
       "      <td>-0.273834</td>\n",
       "      <td>-0.368571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2021Q1</td>\n",
       "      <td>0.081634</td>\n",
       "      <td>0.115155</td>\n",
       "      <td>0.103206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2021Q2</td>\n",
       "      <td>-0.187580</td>\n",
       "      <td>-0.432048</td>\n",
       "      <td>-0.598668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AVENUE</td>\n",
       "      <td>2021Q3</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>3.389139</td>\n",
       "      <td>8.057708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company quarter  revenue_yoy  ebitda_yoy   pat_yoy\n",
       "0  AVENUE  2018Q2          NaN         NaN       NaN\n",
       "1  AVENUE  2019Q2          NaN         NaN       NaN\n",
       "2  AVENUE  2019Q3          NaN         NaN       NaN\n",
       "3  AVENUE  2019Q4          NaN         NaN       NaN\n",
       "4  AVENUE  2020Q1     0.358403    0.037374  0.144687\n",
       "5  AVENUE  2020Q2    -0.336872   -0.736461 -0.852196\n",
       "6  AVENUE  2020Q3    -0.122854   -0.273834 -0.368571\n",
       "7  AVENUE  2021Q1     0.081634    0.115155  0.103206\n",
       "8  AVENUE  2021Q2    -0.187580   -0.432048 -0.598668\n",
       "9  AVENUE  2021Q3     0.995612    3.389139  8.057708"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YoY growth features (within company)\n",
    "model_df_q = model_df_q.sort_values([\"company\", \"quarter\"]).reset_index(drop=True)\n",
    "\n",
    "model_df_q[\"revenue_yoy\"] = (\n",
    "    model_df_q[\"revenue\"] / model_df_q.groupby(\"company\")[\"revenue\"].shift(4) - 1\n",
    ")\n",
    "\n",
    "model_df_q[\"ebitda_yoy\"] = (\n",
    "    model_df_q[\"ebitda\"] / model_df_q.groupby(\"company\")[\"ebitda\"].shift(4) - 1\n",
    ")\n",
    "\n",
    "model_df_q[\"pat_yoy\"] = (\n",
    "    model_df_q[\"pat\"] / model_df_q.groupby(\"company\")[\"pat\"].shift(4) - 1\n",
    ")\n",
    "\n",
    "model_df_q[\n",
    "    [\"company\", \"quarter\", \"revenue_yoy\", \"ebitda_yoy\", \"pat_yoy\"]\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e44634f-9109-4142-929e-7025e8b39509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>revenue_yoy_rel</th>\n",
       "      <th>ebitda_yoy_rel</th>\n",
       "      <th>pat_yoy_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020Q1</td>\n",
       "      <td>0.437696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.211781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  quarter  revenue_yoy_rel  ebitda_yoy_rel  pat_yoy_rel\n",
       "0  2018Q2              NaN             NaN          NaN\n",
       "1  2019Q2              NaN             NaN          NaN\n",
       "2  2019Q3              NaN             NaN          NaN\n",
       "3  2019Q4              NaN             NaN          NaN\n",
       "4  2020Q1         0.437696             0.0     0.211781"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper: subtract quarter-wise median\n",
    "def relative_to_median(df, col):\n",
    "    return df[col] - df.groupby(\"quarter\")[col].transform(\"median\")\n",
    "\n",
    "# create peer-relative features\n",
    "model_df_q[\"revenue_yoy_rel\"] = relative_to_median(model_df_q, \"revenue_yoy\")\n",
    "model_df_q[\"ebitda_yoy_rel\"]  = relative_to_median(model_df_q, \"ebitda_yoy\")\n",
    "model_df_q[\"pat_yoy_rel\"]     = relative_to_median(model_df_q, \"pat_yoy\")\n",
    "\n",
    "model_df_q[\"ebitda_margin_rel\"] = relative_to_median(model_df_q, \"ebitda_margin\")\n",
    "model_df_q[\"pat_margin_rel\"]    = relative_to_median(model_df_q, \"pat_margin\")\n",
    "\n",
    "model_df_q[\n",
    "    [\"quarter\", \"revenue_yoy_rel\", \"ebitda_yoy_rel\", \"pat_yoy_rel\"]\n",
    "].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "107fc5fa-6b71-4b71-8323-8d89393f2317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((380, 26),\n",
       " surprise_q\n",
       " 1.0    190\n",
       " 0.0    190\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target\n",
    "y = model_df_q[\"surprise_q\"]\n",
    "\n",
    "# columns to exclude from features\n",
    "exclude_cols = [\n",
    "    \"surprise\",        # old target\n",
    "    \"surprise_q\",      # new target\n",
    "    \"scaled_surprise\", # continuous target proxy\n",
    "    \"company\",\n",
    "    \"quarter\",\n",
    "    \"eps\"              # never use current EPS\n",
    "]\n",
    "\n",
    "X = model_df_q.drop(columns=exclude_cols)\n",
    "\n",
    "X.shape, y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6750af93-7e8b-4cb1-bd8f-0b7b9f10c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild splits using the new dataset\n",
    "quarters_q = sorted(model_df_q[\"quarter\"].unique())\n",
    "\n",
    "def q_year(q):\n",
    "    return int(q[:4])\n",
    "\n",
    "test_years_q = sorted(set(q_year(q) for q in quarters_q))[2:]  # ensure enough training data\n",
    "\n",
    "splits_q = []\n",
    "\n",
    "for year in test_years_q:\n",
    "    test_quarters = [q for q in quarters_q if q.startswith(str(year))]\n",
    "    train_quarters = [q for q in quarters_q if q < test_quarters[0]]\n",
    "\n",
    "    if len(test_quarters) == 4 and len(train_quarters) > 0:\n",
    "        splits_q.append((train_quarters, test_quarters))\n",
    "\n",
    "len(splits_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e8da1be-a742-4cd1-b2c2-9d22fb5287c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1144: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\acer\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1149: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\acer\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1169: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# logistic regression\u001b[39;00m\n\u001b[32m     23\u001b[39m logit = LogisticRegression(max_iter=\u001b[32m2000\u001b[39m, solver=\u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mlogit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# predictions\u001b[39;00m\n\u001b[32m     27\u001b[39m y_prob = logit.predict_proba(X_test_scaled)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1256\u001b[39m check_classification_targets(y)\n\u001b[32m   1257\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for i, (train_quarters, test_quarters) in enumerate(splits_q):\n",
    "    train_df = model_df_q[model_df_q[\"quarter\"].isin(train_quarters)]\n",
    "    test_df  = model_df_q[model_df_q[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "    X_train = train_df[X.columns]\n",
    "    y_train = train_df[\"surprise_q\"]\n",
    "\n",
    "    X_test = test_df[X.columns]\n",
    "    y_test = test_df[\"surprise_q\"]\n",
    "\n",
    "    # scale (fit only on training)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    # logistic regression\n",
    "    logit = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "    logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # predictions\n",
    "    y_prob = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    final_results.append({\n",
    "        \"fold\": i + 1,\n",
    "        \"test_year\": test_quarters[0][:4],\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc\n",
    "    })\n",
    "\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "final_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb26db55-aad0-4687-a788-3bf7c8d63fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with any missing feature values\n",
    "model_df_q_clean = model_df_q.dropna().reset_index(drop=True)\n",
    "\n",
    "model_df_q_clean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a58c18-15a0-4508-9e56-0629a815aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise_q\n",
       "0.0    157\n",
       "1.0    143\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_q_clean[\"surprise_q\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25a13f8a-6dc8-4f95-9c67-63011180032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 26),\n",
       " surprise_q\n",
       " 0.0    157\n",
       " 1.0    143\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target\n",
    "y = model_df_q_clean[\"surprise_q\"]\n",
    "\n",
    "# columns to exclude from features\n",
    "exclude_cols = [\n",
    "    \"surprise\",\n",
    "    \"surprise_q\",\n",
    "    \"scaled_surprise\",\n",
    "    \"company\",\n",
    "    \"quarter\",\n",
    "    \"eps\"\n",
    "]\n",
    "\n",
    "X = model_df_q_clean.drop(columns=exclude_cols)\n",
    "\n",
    "X.shape, y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d935b5cc-36e5-4b26-b6e6-c4ac4f7424a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild rolling splits on cleaned dataset\n",
    "quarters_clean = sorted(model_df_q_clean[\"quarter\"].unique())\n",
    "\n",
    "def q_year(q):\n",
    "    return int(q[:4])\n",
    "\n",
    "test_years_clean = sorted(set(q_year(q) for q in quarters_clean))[2:]\n",
    "\n",
    "splits_clean = []\n",
    "\n",
    "for year in test_years_clean:\n",
    "    test_quarters = [q for q in quarters_clean if q.startswith(str(year))]\n",
    "    train_quarters = [q for q in quarters_clean if q < test_quarters[0]]\n",
    "\n",
    "    if len(test_quarters) == 4 and len(train_quarters) > 0:\n",
    "        splits_clean.append((train_quarters, test_quarters))\n",
    "\n",
    "len(splits_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa7b2e8-107d-493d-9e2b-b2ec76fdf75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>test_year</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.651709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.737728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.737578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.841739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold test_year  accuracy       auc\n",
       "0     1      2020  0.530612  0.651709\n",
       "1     2      2021  0.490196  0.500000\n",
       "2     3      2022  0.685185  0.737728\n",
       "3     4      2023  0.686275  0.737578\n",
       "4     5      2024  0.770833  0.841739"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for i, (train_quarters, test_quarters) in enumerate(splits_clean):\n",
    "    train_df = model_df_q_clean[model_df_q_clean[\"quarter\"].isin(train_quarters)]\n",
    "    test_df  = model_df_q_clean[model_df_q_clean[\"quarter\"].isin(test_quarters)]\n",
    "\n",
    "    X_train = train_df[X.columns]\n",
    "    y_train = train_df[\"surprise_q\"]\n",
    "\n",
    "    X_test = test_df[X.columns]\n",
    "    y_test = test_df[\"surprise_q\"]\n",
    "\n",
    "    # scale (fit only on training)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    # logistic regression\n",
    "    logit = LogisticRegression(max_iter=3000, solver=\"lbfgs\")\n",
    "    logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # predictions\n",
    "    y_prob = logit.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    final_results.append({\n",
    "        \"fold\": i + 1,\n",
    "        \"test_year\": test_quarters[0][:4],\n",
    "        \"accuracy\": acc,\n",
    "        \"auc\": auc\n",
    "    })\n",
    "\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "final_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acf5fb0-0e61-401e-90f8-f26094ed434d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdf\u001b[49m.shape)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTarget summary:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[\u001b[33m'\u001b[39m\u001b[33mearnings_surprise\u001b[39m\u001b[33m'\u001b[39m].describe())\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nTarget summary:\")\n",
    "print(df['earnings_surprise'].describe())\n",
    "\n",
    "print(\"\\nMissing values (top 15):\")\n",
    "df.isna().sum().sort_values(ascending=False).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0484f2d1-1491-4204-b02e-6dccd76d4d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " 'get_ipython',\n",
       " 'exit',\n",
       " 'quit',\n",
       " 'open',\n",
       " 'json',\n",
       " 'getpass',\n",
       " 'hashlib',\n",
       " 'import_pandas_safely',\n",
       " 'is_data_frame',\n",
       " 'dataframe_columns',\n",
       " 'dtypes_str',\n",
       " 'dataframe_hash',\n",
       " 'get_dataframes',\n",
       " 'pd',\n",
       " 'np']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all variables in memory\n",
    "[var for var in globals().keys() if not var.startswith(\"_\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f04b7b-dd8b-4360-bda1-281f204584b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
